{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing src code\n",
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "# usual suspects\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.signal import fftconvolve, convolve\n",
    "from scipy.linalg import toeplitz, lstsq\n",
    "from scipy.signal import correlate, convolve\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# our stuff\n",
    "import Zero_pad as zp\n",
    "from mask_maker import create_n_channel_data, mel_stft, random_STAT\n",
    "import Conj_grad as cg\n",
    "from rir_estim import RoomResponseEstimator, record_response, calculate_rir\n",
    "\n",
    "# misc\n",
    "import sounddevice as sd\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sd.default.device = 1\n",
    "print (sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sine sweep and estimator\n",
    "fs = 44100\n",
    "estimator = RoomResponseEstimator(duration=2.0, low=30.0, high=15000.0, Fs=fs)\n",
    "sine_sweep = estimator.probe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record all responses\n",
    "n_speakers = 6\n",
    "n_mic = 2\n",
    "responses = [[[] for i in range(n_speakers)] for j in range(n_mic)]\n",
    "for i in range(n_speakers):\n",
    "    resp  = record_response(sine_sweep, i , fs, fs, n_mic, verbose = False)\n",
    "    resp_array = np.asarray(resp)\n",
    "    for j in range(n_mic):\n",
    "        responses[j][i].append(list(resp_array[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate RIRs\n",
    "RIRS = [[[] for i in range(n_speakers)] for j in range(n_mic)]\n",
    "for i in range(n_speakers):\n",
    "    for j in range(n_mic):\n",
    "        rir = calculate_rir(responses[j][i][0], 1024, estimator, shorten = 25000, verbose = False)\n",
    "        RIRS[j][i].append(rir)\n",
    "        \n",
    "for i in range(n_speakers):\n",
    "    for j in range(n_mic):\n",
    "        RIRS[j][i] = RIRS[j][i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of the jointly optimization process\n",
    "# Variables we can play with\n",
    "M = 100000 # filter length\n",
    "delay = 10000 # delay of the signals in number of samples\n",
    "n_speaker = 6\n",
    "\n",
    "# Read in the original sound signals\n",
    "n_signals = 2\n",
    "fs = np.empty((n_signals,), dtype=object)\n",
    "orig_sound = np.empty((n_signals,), dtype=object)\n",
    "[fs[0], orig_sound[0]] = wav.read('../sounds/news.wav')\n",
    "[fs[1], orig_sound[1]] = wav.read('../sounds/metalking_44k.wav')\n",
    "\n",
    "\n",
    "#This is for clipping to 4 sec\n",
    "orig_sound[0] = 2.3/3.*orig_sound[0][5*fs[0]:5*fs[0] + 7*fs[0]]\n",
    "orig_sound[1] = orig_sound[1][:7*fs[1]] * 0\n",
    "\n",
    "# Zero pad the shorter signals so that each signal has the same length\n",
    "# Also, at the same time obtain the delayed version of the signal\n",
    "length = []\n",
    "for i in range(n_signals):\n",
    "    length.append(len(orig_sound[i]))\n",
    "\n",
    "sig_length = max(length)\n",
    "\n",
    "delay_sound = np.empty((n_signals,), dtype=object)\n",
    "for i in range(n_signals):\n",
    "    delay_sound[i] = zp.front_pad(\n",
    "        zp.back_pad(orig_sound[i], (sig_length - len(orig_sound[i]))), delay).astype(np.int16)\n",
    "    orig_sound[i] = zp.back_pad(orig_sound[i] , (sig_length - len(orig_sound[i]) + delay)).astype(np.int16)\n",
    "\n",
    "mean = 0\n",
    "std = 10 \n",
    "num_samples = len(orig_sound[0])\n",
    "orig_sound[0] = 250 * np.random.normal(mean, std, size=N)\n",
    "orig_sound[1] = 250 * np.random.normal(mean, std, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(orig_sound[0], rate = fs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(orig_sound[1], rate = fs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero pad the RIRs so that they have the same length\n",
    "rir_length = []\n",
    "for i in range(n_mic):\n",
    "    for j in range(n_speaker):\n",
    "        rir_length.append(len(RIRS[i][j]))\n",
    "K = max(rir_length)\n",
    "\n",
    "for i in range(n_mic):\n",
    "    for j in range(n_speaker):\n",
    "        RIRS[i][j] = zp.back_pad(RIRS[i][j] , K - len(RIRS[i][j]))\n",
    "\n",
    "# Parameters for chopping\n",
    "num_samples_shift = 100\n",
    "samples_per_chunk = 500\n",
    "speaker_offset = 0\n",
    "        \n",
    "# Obtain the chopped signals and the masks\n",
    "speaker_data = np.empty((n_signals,), dtype=object)\n",
    "mask = np.empty((n_signals,), dtype=object)\n",
    "for i in range(n_signals):\n",
    "    speaker_data[i], mask[i] = np.asarray(\n",
    "        create_n_channel_data(num_samples_shift, samples_per_chunk , speaker_offset, orig_sound[i], n_speaker, random_cycling = True))\n",
    "\n",
    "# Form the target b vector and pass the parameters into the CG method to calculate for the filter g\n",
    "b = []\n",
    "for i in range(n_signals):\n",
    "    b.append(zp.back_pad(list(delay_sound[i]), M+N+K - 2 - len(delay_sound[i]))) # Matching up the dimension\n",
    "b_vec = np.array(b).flatten()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num = 100 # number of iterations for our CG\n",
    "g_hat = cg.create_ghat(speaker_data, b_vec, iter_num, n_signals, RIRS, M , init_guess = 'uni_random', plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the filter g_hat for each speaker / each focusing zone\n",
    "g_hat_len = len(g_hat)\n",
    "g_hat_speaker = []\n",
    "for i in range(n_speakers*n_signals):\n",
    "    g_hat_speaker.append(g_hat[int(i*(g_hat_len/n_signals/n_speakers)):int((i+1)*(g_hat_len/n_signals/n_speakers))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_play = []\n",
    "count = 0\n",
    "for i in range(n_speakers):\n",
    "    y_play_sum = np.zeros((len(speaker_data[0][:, 0]) + len(g_hat_speaker[count]) - 1,))\n",
    "    \n",
    "    for j in range(n_signals):\n",
    "        y_play_sum += convolve( speaker_data[j][:, i], g_hat_speaker[count])\n",
    "        count += 1\n",
    "        \n",
    "    y_play.append(y_play_sum)\n",
    "    \n",
    "    print(y_play[i].shape)\n",
    "    plt.figure()\n",
    "    plt.title('Signal chunk * filter')\n",
    "    plt.plot(y_play[i])\n",
    "    plt.show()\n",
    "    \n",
    "y_play = np.asarray(y_play)\n",
    "print(y_play.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_signal = np.zeros( (len(y_play[0]), n_speakers))\n",
    "for i in range(n_speakers):\n",
    "    final_signal[:,i] = y_play[i]\n",
    "\n",
    "# pad so that soundevice will keep recording and we can grab the last echoes\n",
    "padded_final_signal = np.vstack( ( final_signal, np.zeros( ( 44100 , n_speakers ) ) ) )\n",
    "padded_final_signal *= .0000008 # arbitrary scaling factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This actually plays and records\n",
    "num_mics_total = 5\n",
    "y_mic = sd.playrec( padded_final_signal , fs[0], channels=num_mics_total )\n",
    "sd.wait()\n",
    "\n",
    "for i in range(num_mics_total):\n",
    "    display(Audio( y_mic[:,i], rate = fs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
